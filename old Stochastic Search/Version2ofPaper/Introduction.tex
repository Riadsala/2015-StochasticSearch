\section{Introduction}

Visual search is a common task which we encounter daily in real life. Within the confines of the laboratory search tasks frequently involve searching within an image for a designated target item. A complete computational model of visual search should contain two parts: a \itshape feature extraction mechanism \normalfont and a \itshape search strategy\normalfont. The feature extraction stage takes information from the stimulus and processes it in order to produce an activation map. This process should take both top-down guided search \citep{wolfe2007, zelinsky2008} and bottom-up saliency effects \citep{itti-koch2000, gao2008, itti-baldi2009} into account. For the sets of abstract, discrete search items commonly used as visual search stimuli, categorical features such as colour, orientation, shape and size are often used. Simple qualitative comparisons between the search items and the target are can be used to model top-down guidance \citep{pomplun2003, rutishauser-koch2007}. For more complex stimuli, such as a target hidden in image noise or in a photograph of a natural scene, we no longer have a discrete set of items to consider and  more sophisticated image processing techniques are required \citep{rao2002, zelinsky2008, pomplun2007,  hwang2009, tavassoli2009}.

\par

This study, however, is concerned with search strategies: the part of a model that uses an activation map to generate successive saccades. While a number of different mechanisms have been put forward, the most commonly implemented has been the maximum a priori (MAP) Observer. This strategy simply directs saccades to the current maximum of the activation map. A simple inhibition of return (IOR) mechanism is used to stop the model returning to previously fixated maxima and depending on the model, a maximum will either represent a search item, or the centre of gravity of a number of search items. As most previous computational models have primarily been interested in the feature extraction stage of search, this strategy has often been used for simplicity \citep{itti-koch2000, rao2002, pomplun2003, rutishauser-koch2007, clarke2009, zelinsky2008}.
 
\par

An alternative to the MAP Observer is the Ideal Observer which \cite{najemnik-geisler2005, najemnik-geisler2008} have derived for a search task involving a target hidden in $1/f$-noise. Their model is based on visibility maps calculated from empirical data collected during a signal detection experiment. These maps are used to control how much noise is added to potential target locations (with more noise at higher eccentricities) in the simulations. The Ideal Observer then makes saccades to the target location that will maximise the likelihood of it being able to identify the target during the following fixation. This contrasts with strategies where the model makes a saccade to the location which is currently most likely to be the target. In a second experiment observers carried out a prolonged search using similar stimuli. The results showed that over a range of task difficulties human observers take a similar number of saccades to the Ideal Observer. Furthermore, when averaged over all trials the Ideal Observer matched the spatial distribution of fixations: both the model and human observers exhibited a preference for fixating above and below the centre of the image. 
\par
Models like these are examples of systematic search. Broadly, systematic search can be made up from two types of behaviour. Firstly, the search could be controlled by image properties, in either a bottom-up or top-down manner, or a combination of both. Both the Guided Search \citep{wolfe2007} and saliency \citep{itti-koch2000} models fall into this category. Secondly, search strategies can also involve some serial dependence between one fixation and the next. This can include both memory processes (for example, inhibition of return) and regular scanning. However, some models, such as Rutishauser and Koch's probabilistic model [\citeyear{rutishauser-koch2007}] introduce a random element. The aim of this paper is to investigate whether, in a particular type of search task, an entirely random model of saccade selection can account for empirically recorded scan paths.

\par
Several general tendencies observed in scan-paths have been taken to be indicative of systematic search strategies. \cite{gilchrist-harvey2006} argue that the presence of horizontal bias in saccade directions indicates a systematic component in visual search and suggest that systematic tendencies can be hard to detect in scan-paths because of the interaction with salience-based object selection. Similarly, \cite{over2007} have shown that search scan-paths exhibit coarse-to-fine structures, i.e. observers make shorter saccades as a trial progresses. \cite{over2003} found that saccade directions are influenced by the edges of the search image and reported a preference for making saccades parallel to the boundaries of the stimuli. 
\par
Aks et al have argued that the presence of  $1/f$ dynamics in saccade-time series is evidence of a systematic component in visual search that relies on memory of previous fixation locations \citep{aks2002, aks2005}. They carried out the same time-series analysis on a random walk and found that it did not exhibit the same properties. However it is possible that Aks' result is an artefact of studying the compound time-series of large number of visual searches, one after another. If we were to look at the saccade amplitude time-series of several individual searches, each with a coarse-to-fine dynamic, then we would expect to see a strong low frequency component which could, at least partially, explain Aks et al.'s result. Similarly, \itshape distance-to-target \normalfont dynamics have been put forwards as evidence for some systematic component in visual search \citep{tseng-li2004}. These dynamics suggest that there are two phases to the search process: an ineffective stage, followed by an effective stage in which the distance from the current fixation location to the target decreases monotonically. However Greene has shown that these dynamics also arise in simple random walk simulations \citep{greene2008}. These simulations generated saccades at random and the target was assumed to be detected if it was within 20 pixels of the current fixation, and the model was given a maximum of 15 saccades to find the target. Further support for the idea of unsystematic visual search comes from several studies which show that memory only plays a small role in visual search tasks \citep{horowitz-wolfe1998, horowitz-wolfe2001, kuna2008, wolfe2000}. 
\par
Chance has been demonstrated to play a significant role in visual search performance. Using saccade amplitude distributions \cite{motter-holsapple2001} calculated the probability of fixating on the target by chance under different conditions. While this chance component decreases as the number of distracters increase, it continues to account for a sizeable fraction of performance. Random walks have been successfully used to model an observer's speed and accuracy in present/absent forced choice experiments \citep{stone1960, reeves2005}. Rather than model the spatial distribution of fixations these models simulate the observer's decision making process. The random walk occurs between two boundaries one for a target present response and one for target absent, and is governed by a drift and bias. 
\par
Overall, while there is strong evidence for systematic search in many tasks, the random element is stronger than we might expect in many others. However there is no clear evidence yet for purely random-walk search. In this paper we investigate just this, and ask if there are situations and stimuli for which a random-walk is a good model for human observers. A good place to look for such behaviour would be with simple stimuli (to avoid high-level semantic information from being used) containing a difficult to find target, such as a target embedded in noise. We have chosen to use fractal surfaces, which when illuminated give the appearance of a naturalistic surface texture \citep{clarke2008}. See Figure \ref{fig:smooth} for an example. These surfaces have two advantages over traditional visual search stimuli. Firstly, unlike the arrays of abstract discrete geometric objects that are often used, they appear naturalistic. Furthermore, unlike photographs of natural scenes, they are fully controlled and parametrised, and by controlling the seed of the random number generator many different, yet equivalent, textures can be created.
\par

\begin{figure}
	\centering
		\includegraphics[width=\textwidth, bb=0 0 1024 1024]{figures/smooth512.png}
		\caption{An example $1/f^{\beta}$-noise surface. Note: this example is only $512\times 512$ pixels. the stimuli used in the experiment where $1024\times 1024$, while the target dent stayed the same size.}
	\label{fig:smooth}
\end{figure}

Previous attempts to model search on such surfaces have used filter based image processing models \citep{clarke2009}. However, while this model gives a good account of human performance, in terms of the number of saccades required to find the target, it fails to account for the pattern of fixations made by human observers and there was no apparent relationship between human fixation locations and (non-target) local maxima in the activation map: only 22\% of the model's potential saccade targets were located within $1^{\circ}$ of the saccade target chosen by a human observer. Further analysis (see Appendix \ref{appendix:LNL}) shows the model's saccade target can be expected to coincide with the human saccade target 19\% of the time if saccades are made at random. Furthermore, human observers often make long saccades that cannot be explained using the eccentricity dependant fall-off in activation.
\par
In this study, in order to investigate search strategy only, we will assume a feature extraction mechanism and use an empirical visibility model based on the results of a signal detection experiment as the starting point for the search strategy. This mirrors Najemnik and Geisler's methods [\citeyear{najemnik-geisler2005}]. However, we will use the visibility model in conjunction with a stochastic process which draws saccade amplitudes and directions from empirically derived distributions. This will allow us to determine whether a simple random walk model is sufficient to account for human saccade paths in our task. 
\par
Note that there are two differences between the stimuli used by Najemnik and Geisler and ours. Firstly they used $1/f$-noise as their stimuli whereas we have combined $1/f$-noise with an illumination model to give surfaces that appear naturalistic \citep{clarke2008}. Secondly, they consider only 85 potential target locations, whereas in our stimuli the target can be centred at any pixel within a given distance from the centre. While we would not expect human observers to notice this difference, the lower number did considerably simplify the derivation of the Ideal Observer. If the target is allowed to be positioned anywhere in the stimuli, then the independence assumption required by the Ideal Observer model is no longer valid.
